{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "from io import StringIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x117af44a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "cred = credentials.Certificate('key.json')  \n",
    "firebase_admin.initialize_app(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudarshan/anaconda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predictor_model(X, y):\n",
    "    logistic_classifier = LogisticRegressionCV()\n",
    "    \n",
    "    logistic_classifier.fit(X, y)\n",
    "    print(\"Classifier Accuracy:\", logistic_classifier.score(X, y))\n",
    "    return logistic_classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictor_model(model, name):\n",
    "    filename = '{}.sav'.format(name)\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    bucket_name = \"ieor185-274323.appspot.com\"\n",
    "    source_file_name = filename\n",
    "    destination_blob_name = name\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json('key.json')\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        \"File {} uploaded to {}.\".format(\n",
    "            source_file_name, destination_blob_name\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    os.remove(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data, column):\n",
    "    if column not in data.columns:\n",
    "        return data\n",
    "    \n",
    "    vec_enc = DictVectorizer()\n",
    "    vec_enc.fit(data[[column]].to_dict(orient='records'))\n",
    "    fireplace_qu_data = vec_enc.transform(data[[column]].to_dict(orient='records')).toarray()\n",
    "    fireplace_qu_cats = vec_enc.get_feature_names()\n",
    "    fireplace_qu = pd.DataFrame(fireplace_qu_data, columns=fireplace_qu_cats)\n",
    "    data = pd.concat([data, fireplace_qu], axis=1)\n",
    "    \n",
    "    data = data.drop(columns=[fireplace_qu_cats[0], column])\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_input_data(df):\n",
    "    df = df.reset_index()\n",
    "    X = df.iloc[:,1:-4]\n",
    "    Y = df.iloc[:,-4:]\n",
    "    \n",
    "    # Data Sanitization\n",
    "    X['has_roommates'] = X['has_roommates'].apply(lambda x: 1 if x.lower() == 'y' else 0)\n",
    "    X['percent_work_done_in_teams'] = X['percent_work_done_in_teams'].apply(lambda x: float(str(x)[:-1])/100)\n",
    "    X['public_transit_commute'] = X['public_transit_commute'].apply(lambda x: 1 if x.lower() == 'y' else 0)\n",
    "    X['lunch_cafeteria_or_other'] = X['lunch_cafeteria_or_other'].apply(lambda x: 1 if x.lower() == 'c' else 0)\n",
    "    X['gender'] = X['gender'].apply(lambda x: 1 if x.lower() == 'male' else 0)\n",
    "    \n",
    "    X = one_hot_encoding(X.copy(), \"location\")    \n",
    "    X = one_hot_encoding(X.copy(), \"season\")\n",
    "\n",
    "    return X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(df):\n",
    "    X, Y = sanitize_input_data(df)    \n",
    "    # Dataset - Depression\n",
    "    X_depression, y_depression = X.copy(), Y.iloc[:,0]\n",
    "    depression_model = build_predictor_model(X_depression, y_depression)\n",
    "    save_predictor_model(depression_model, \"sore throat\")\n",
    "    \n",
    "    # Dataset - SAD\n",
    "    X_sad, y_sad = X.copy(), Y.iloc[:,1]\n",
    "    sad_model = build_predictor_model(X_sad, y_sad)\n",
    "    save_predictor_model(depression_model, \"fever\")\n",
    "    \n",
    "    # Dataset - Lombago\n",
    "    X_lombago, y_lombago = X.copy(), Y.iloc[:,2]\n",
    "    lombago_model = build_predictor_model(X_lombago, y_lombago)\n",
    "    save_predictor_model(depression_model, \"cough\")\n",
    "    \n",
    "    # Dataset - Carpal Tunnel\n",
    "    X_ct, y_ct = X.copy(), Y.iloc[:,3]\n",
    "    ct_model = build_predictor_model(X_ct, y_ct)\n",
    "    save_predictor_model(depression_model, \"allergy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_firebase():\n",
    "    keys_all = ['age', 'gender', 'weight', 'num_task_pending',\n",
    "       'average_task_completion_delay', 'avg_sleep', 'calories_eaten',\n",
    "       'water_drank', 'lunch_cafeteria_or_other', 'percent_work_done_in_teams',\n",
    "       'public_transit_commute', 'entry time', 'exit time', 'hours', 'height',\n",
    "       'num_breaks', 'season', 'location', 'has_roommates', 'num_laundry',\n",
    "        \"sore throat\",\"fever\",\"cough\",\"allergy symptoms\"]\n",
    "    \n",
    "    db = firestore.client()\n",
    "    \n",
    "    docs = db.collection(u'health_prediction').get()\n",
    "    rows = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        rows.append(doc.to_dict())\n",
    "        \n",
    "    return pd.DataFrame(data=rows, columns=keys_all).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Accuracy: 0.5714285714285714\n",
      "File sore throat.sav uploaded to sore throat.\n",
      "Classifier Accuracy: 0.9387755102040817\n",
      "File fever.sav uploaded to fever.\n",
      "Classifier Accuracy: 0.673469387755102\n",
      "File cough.sav uploaded to cough.\n",
      "Classifier Accuracy: 1.0\n",
      "File allergy.sav uploaded to allergy.\n"
     ]
    }
   ],
   "source": [
    "df = load_input_firebase()\n",
    "create_models(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
